{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EbdfksF7GPx3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U75SIJHkNbTL"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vYlwRfSDXxi",
        "outputId": "5141ac59-6ae1-407c-8226-e61e038b214c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-06-29 12:19:44--  http://=/\n",
            "Resolving = (=)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘=’\n",
            "The name is too long, 784 chars total.\n",
            "Trying to shorten...\n",
            "New name is fruits-360-original-size.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com%2F20230629%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230629T121925Z&X-Goog-Expires=259200&X-Goog-.\n",
            "--2023-06-29 12:19:44--  https://storage.googleapis.com/kaggle-data-sets/5857/2609027/compressed/fruits-360-original-size.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230629%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230629T121925Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=10ebabd38fbf3a751a498a0cc6a441fd6ee5ebc6dc6c6cdf32fb17cad4cc76f57a8488fc3f1caf6b3e2b9e46136f9c0d33118f88dce728f5289313aa68e817c6dc7e301c5b5fafc9d5cfefbbb92816dee7fa4e5cac8ea8cdbd312225428f9b07e2e6ac9fa1ace1bd31a83cd342927f04d08c15a8e2cf926173e107885ac7fdfd2695ff9d5c1ffec4e6bfa747e27dc903b7bae693c0b5603608cc72754fa62c391ec64787531a1a49b03f9a370e93c57c8ce7083ebb8e492258f0b6b5b9093adf61ab99eff1d2d34dfea37146e32e2152a8d98eaf24607b1e1105806c75ed7b1fa596f6290589240493ac7032dbb7b5e4a41ca15a262fcc28026b3ffeb4099329\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.126.128, 74.125.70.128, 74.125.132.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.126.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 578873667 (552M) [application/zip]\n",
            "Saving to: ‘fruits-360-original-size.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com%2F20230629%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230629T121925Z&X-Goog-Expires=259200&X-Goog-’\n",
            "\n",
            "fruits-360-original 100%[===================>] 552.06M  84.7MB/s    in 5.2s    \n",
            "\n",
            "2023-06-29 12:19:49 (107 MB/s) - ‘fruits-360-original-size.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com%2F20230629%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230629T121925Z&X-Goog-Expires=259200&X-Goog-’ saved [578873667/578873667]\n",
            "\n",
            "FINISHED --2023-06-29 12:19:49--\n",
            "Total wall clock time: 5.3s\n",
            "Downloaded: 1 files, 552M in 5.2s (107 MB/s)\n"
          ]
        }
      ],
      "source": [
        "!wget = \"https://storage.googleapis.com/kaggle-data-sets/5857/2609027/compressed/fruits-360-original-size.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230629%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230629T121925Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=10ebabd38fbf3a751a498a0cc6a441fd6ee5ebc6dc6c6cdf32fb17cad4cc76f57a8488fc3f1caf6b3e2b9e46136f9c0d33118f88dce728f5289313aa68e817c6dc7e301c5b5fafc9d5cfefbbb92816dee7fa4e5cac8ea8cdbd312225428f9b07e2e6ac9fa1ace1bd31a83cd342927f04d08c15a8e2cf926173e107885ac7fdfd2695ff9d5c1ffec4e6bfa747e27dc903b7bae693c0b5603608cc72754fa62c391ec64787531a1a49b03f9a370e93c57c8ce7083ebb8e492258f0b6b5b9093adf61ab99eff1d2d34dfea37146e32e2152a8d98eaf24607b1e1105806c75ed7b1fa596f6290589240493ac7032dbb7b5e4a41ca15a262fcc28026b3ffeb4099329\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xn0oa9Yiu8Z",
        "outputId": "880031ed-7da2-4e30-8628-64b214bf1832"
      },
      "outputs": [],
      "source": [
        "!unzip master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "305CTYBUkAOk"
      },
      "outputs": [],
      "source": [
        "train_data_dir = '/content/fruits-360-original-size/Training'\n",
        "validation_data_dir = '/content/fruits-360-original-size/Validation'\n",
        "test_data_dir = '/content/fruits-360-original-size/Test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEQTgR0xvfQf",
        "outputId": "c6d7af6f-d2c6-4df4-b34b-3a4579ba9e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 24\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset_folder = '/content/fruits-360-original-size/Training'\n",
        "\n",
        "classes = os.listdir(dataset_folder)\n",
        "\n",
        "num_classes = len(classes)\n",
        "\n",
        "print(\"Number of classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VBMxdVCFb5vN"
      },
      "outputs": [],
      "source": [
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "num_epochs = 15\n",
        "num_classes = 24\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tsEvbFPMkwiE"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "J-nMgqEfcszo"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.ImageFolder(train_data_dir, train_transform)\n",
        "validation_dataset = datasets.ImageFolder(validation_data_dir, val_transform)\n",
        "test_dataset = datasets.ImageFolder(test_data_dir, test_transform)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y5XjQqQbeZqy"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wyNG59Teaub",
        "outputId": "65b5afdb-f491-49d7-c7ff-e772ed77864b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 132MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.mobilenet_v2(pretrained=True)\n",
        "num_features = model.classifier[1].in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(num_features, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, num_classes)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AFAIgXupejw1"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum = 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3rfPLJJoejy9"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuUmPUj0ekUT",
        "outputId": "62bc2990-8d2c-4b4b-bca1-fd633bf53bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.0705\n",
            "Validation Loss: 2.8813 Acc: 0.3423\n",
            "Train Loss: 2.7805\n",
            "Validation Loss: 2.4231 Acc: 0.5148\n",
            "Train Loss: 2.3605\n",
            "Validation Loss: 1.8700 Acc: 0.7103\n",
            "Train Loss: 1.8883\n",
            "Validation Loss: 1.3748 Acc: 0.8099\n",
            "Train Loss: 1.4641\n",
            "Validation Loss: 0.9980 Acc: 0.8671\n",
            "Train Loss: 1.1499\n",
            "Validation Loss: 0.7550 Acc: 0.9107\n",
            "Train Loss: 0.9174\n",
            "Validation Loss: 0.5603 Acc: 0.9467\n",
            "Train Loss: 0.7546\n",
            "Validation Loss: 0.4117 Acc: 0.9862\n",
            "Train Loss: 0.6144\n",
            "Validation Loss: 0.3054 Acc: 0.9949\n",
            "Train Loss: 0.5109\n",
            "Validation Loss: 0.2228 Acc: 0.9990\n",
            "Train Loss: 0.4223\n",
            "Validation Loss: 0.1666 Acc: 1.0000\n",
            "Train Loss: 0.3614\n",
            "Validation Loss: 0.1226 Acc: 1.0000\n",
            "Train Loss: 0.3107\n",
            "Validation Loss: 0.1025 Acc: 1.0000\n",
            "Train Loss: 0.2630\n",
            "Validation Loss: 0.0813 Acc: 1.0000\n",
            "Train Loss: 0.2469\n",
            "Validation Loss: 0.0695 Acc: 1.0000\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f'Train Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_corrects = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    val_loss = val_loss / len(validation_dataset)\n",
        "    val_acc = val_corrects.double() / len(validation_dataset)\n",
        "    print(f'Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-w8PsXqe3mM",
        "outputId": "10f61dad-7b0b-48e7-b95e-e06b471b2346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Acc: 0.9997\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "test_corrects = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        test_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "test_acc = test_corrects.double() / len(test_dataset)\n",
        "print(f'Test Acc: {test_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Bwhq8rite4Bc"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'FruitsClass360.pth')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
